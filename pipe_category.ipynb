{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit (conda)",
   "metadata": {
    "interpreter": {
     "hash": "e55c523ff2bbb618fbe24525858e914d64cf59e5e868795d6cd1f87bc7cc8e1c"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lib Imports\n",
    "import pandas as pd\n",
    "import os\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Lasso, LogisticRegression, LinearRegression, LassoCV\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import category_encoders as ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting Pandas column display option\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "idee = pd.read_csv('train_identity.csv')\n",
    "transaction = pd.read_csv('train_transaction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "def pipeline(idee, transaction):\n",
    "    merge = transaction.merge(idee, how='outer', on='TransactionID')\n",
    "    objects = merge.select_dtypes('object')\n",
    "    objects = objects.join(merge[['card1', 'card2', 'card3', 'card5', 'addr1', 'addr2']])\n",
    "    objects['isFraud'] = merge['isFraud']\n",
    "    objects.fillna(\"Unknown\", inplace=True)\n",
    "    objects = objects.astype('category')\n",
    "    print(objects.info())\n",
    "    return objects\n",
    "objects = pipeline(idee,transaction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objects.drop(columns=['M4','id_15','id_16','id_28','id_29','id_35','id_36','id_38','DeviceType','DeviceInfo'], inplace=True)\n",
    "objects.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#value_counts_list = []\n",
    "#obj_columns_list = objects.columns.to_list()\n",
    "#for column in obj_columns_list:\n",
    "    #df = objects[column].value_counts().reset_index()\n",
    "    #value_counts_list.append(df)\n",
    "\n",
    "#objects_value_counts_df = pd.concat(value_counts_list, axis=1)\n",
    "#objects_value_counts_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "X  = objects.drop(columns='isFraud')\n",
    "y = objects['isFraud'].astype('int')\n",
    "\n",
    "under = RandomUnderSampler(sampling_strategy=0.8) \n",
    "over = RandomOverSampler(sampling_strategy=0.5)\n",
    "# sm = SMOTE()\n",
    "# ad = ADASYN()\n",
    "# lasso = LassoCV(tol=0.01, n_jobs=-1)\n",
    "\n",
    "#X_rus, y_rus = under.fit_resample(X, y)\n",
    "X_ros, y_ros = over.fit_resample(X, y)\n",
    "# X_sm, y_sm = sm.fit_resample(X, y)\n",
    "# X_ad, y_ad = ad.fit_resample(X, y)\n",
    "X_cs, y_cs = under.fit_resample(X_ros, y_ros)\n",
    "del X_ros, y_ros\n",
    "\n",
    "def split(X,y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=123)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "logit = LogisticRegression(\n",
    "        penalty='l2', C=1e42, max_iter=500, verbose=1, solver='liblinear', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = split(X_cs, y_cs)\n",
    "\n",
    "columns = X_train.columns.to_list()\n",
    "\n",
    "def get_score(model, X, y, X_test, y_test):\n",
    "    model.fit(X, y)\n",
    "    y_pred = model.predict_proba(X_test)[:,1]\n",
    "    score = roc_auc_score(y_test, y_pred)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# n_components_list = np.arange(100, 500, 100).tolist()\n",
    "n_components_list = [1000]\n",
    "n_components_list_str = [str(i) for i in n_components_list]\n",
    "\n",
    "fh_logit_scores = []\n",
    "\n",
    "for n_components in n_components_list:\n",
    "    hashing_enc = ce.HashingEncoder(cols=columns, n_components=n_components, max_process=4).fit(X_train, y_train)\n",
    "    \n",
    "    X_train_hashing = hashing_enc.transform(X_train.reset_index(drop=True))\n",
    "    print(X_train_hashing.shape)\n",
    "    X_test_hashing = hashing_enc.transform(X_test.reset_index(drop=True))\n",
    "    print(X_test_hashing.shape)\n",
    "\n",
    "    fe_logit_score = get_score(logit, X_train_hashing, y_train, X_test_hashing, y_test)\n",
    "    fh_logit_scores.append(fe_logit_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(n_components_list_str, fh_logit_scores, linewidth=3)\n",
    "plt.title('n_compontents vs roc_auc for feature hashing with logistic regression')\n",
    "plt.xlabel('n_components')\n",
    "plt.ylabel('score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fh_logit_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "growth_rate = np.exp(np.diff(np.log(fh_logit_scores))) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "growth_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(n_components_list_str, growth_rate, linewidth=3)\n",
    "plt.title('n_compontents vs growth_rate for feature hashing with logistic regression')\n",
    "plt.xlabel('n_components')\n",
    "plt.ylabel('GRate')\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "## Test dataset benchmarking"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "hashing_enc = ce.HashingEncoder(cols=columns, n_components=1600, max_process=4).fit(X_train, y_train)\n",
    "X_train_hashing = hashing_enc.transform(X_train.reset_index(drop=True))\n",
    "X_test_hashing = hashing_enc.transform(X_test.reset_index(drop=True))\n",
    "print(X_train_hashing.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "idee_test = pd.read_csv('test_identity.csv')\n",
    "transaction_test = pd.read_csv('test_transaction.csv') \n",
    "merge_test = transaction_test.merge(idee_test, how='outer', on='TransactionID')\n",
    "objects_test = merge_test.select_dtypes('object')\n",
    "objects_test.fillna(\"Unknown\", inplace=True)\n",
    "objects_test = objects_test.astype('category')\n",
    "objects_test.columns = X_train.columns\n",
    "print(objects_test.info())\n",
    "del idee_test, transaction_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2_hashed = hashing_enc.transform(objects_test.reset_index(drop=True), override_return_df=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "X2_hashed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "logit.fit(X_train_hashing, y_train)\n",
    "y_pred_train = logit.predict(X_test_hashing)\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_pred_train, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "y_pred = logit.predict(X2_hashed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  }
 ]
}