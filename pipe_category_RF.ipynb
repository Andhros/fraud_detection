{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lib Imports\n",
    "import pandas as pd\n",
    "import os\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, roc_auc_score, classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "from imblearn.ensemble import RUSBoostClassifier\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import category_encoders as ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting Pandas column display option\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Wall time: 16 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "idee = pd.read_csv('train_identity.csv')\n",
    "transaction = pd.read_csv('train_transaction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nInt64Index: 590540 entries, 0 to 590539\nData columns (total 38 columns):\n #   Column         Non-Null Count   Dtype \n---  ------         --------------   ----- \n 0   ProductCD      590540 non-null  object\n 1   card4          590540 non-null  object\n 2   card6          590540 non-null  object\n 3   P_emaildomain  590540 non-null  object\n 4   R_emaildomain  590540 non-null  object\n 5   M1             590540 non-null  object\n 6   M2             590540 non-null  object\n 7   M3             590540 non-null  object\n 8   M4             590540 non-null  object\n 9   M5             590540 non-null  object\n 10  M6             590540 non-null  object\n 11  M7             590540 non-null  object\n 12  M8             590540 non-null  object\n 13  M9             590540 non-null  object\n 14  id_12          590540 non-null  object\n 15  id_15          590540 non-null  object\n 16  id_16          590540 non-null  object\n 17  id_23          590540 non-null  object\n 18  id_27          590540 non-null  object\n 19  id_28          590540 non-null  object\n 20  id_29          590540 non-null  object\n 21  id_30          590540 non-null  object\n 22  id_31          590540 non-null  object\n 23  id_33          590540 non-null  object\n 24  id_34          590540 non-null  object\n 25  id_35          590540 non-null  object\n 26  id_36          590540 non-null  object\n 27  id_37          590540 non-null  object\n 28  id_38          590540 non-null  object\n 29  DeviceType     590540 non-null  object\n 30  DeviceInfo     590540 non-null  object\n 31  card1          590540 non-null  object\n 32  card2          590540 non-null  object\n 33  card3          590540 non-null  object\n 34  card5          590540 non-null  object\n 35  addr1          590540 non-null  object\n 36  addr2          590540 non-null  object\n 37  isFraud        590540 non-null  object\ndtypes: object(38)\nmemory usage: 191.8+ MB\nNone\nWall time: 14.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def pipeline(idee, transaction):\n",
    "    merge = transaction.merge(idee, how='outer', on='TransactionID')\n",
    "    objects = merge.select_dtypes('object')\n",
    "    objects = objects.join(merge[['card1', 'card2', 'card3', 'card5', 'addr1', 'addr2']])\n",
    "    objects['isFraud'] = merge['isFraud']\n",
    "    objects.fillna(\"Unknown\", inplace=True)\n",
    "    objects = objects.astype('object')\n",
    "    #objects = objects.astype('category')\n",
    "    print(objects.info())\n",
    "    return objects\n",
    "objects = pipeline(idee,transaction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(590540, 38)\n0    569877\n1     20663\nName: isFraud, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# objects.drop(columns=['M4','id_15','id_16','id_28','id_29','id_35','id_36','id_38','DeviceType','DeviceInfo'], inplace=True)\n",
    "print(objects.shape)\n",
    "print(objects.isFraud.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Wall time: 1.15 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X  = objects.drop(columns='isFraud')\n",
    "y = objects['isFraud'].astype('int') \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=123)\n",
    "\n",
    "bbc = BalancedBaggingClassifier(base_estimator=DecisionTreeClassifier(),\n",
    "                                sampling_strategy='all',\n",
    "                                replacement=False,\n",
    "                                random_state=0,\n",
    "                                n_estimators=100)\n",
    "\n",
    "brf = BalancedRandomForestClassifier(sampling_strategy='auto',\n",
    "                                     replacement=False,\n",
    "                                     random_state=0,\n",
    "                                     n_estimators=100,\n",
    "                                     n_jobs=-1)\n",
    "\n",
    "rf = RandomForestClassifier(random_state=0,\n",
    "                            class_weight='balanced',\n",
    "                            n_estimators=100,\n",
    "                            n_jobs=-1)\n",
    "\n",
    "bada = RUSBoostClassifier(base_estimator=AdaBoostClassifier(),\n",
    "                         sampling_strategy='auto',\n",
    "                         replacement=True,\n",
    "                         random_state=0,\n",
    "                         n_estimators=100)\n",
    "\n",
    "dtc = DecisionTreeClassifier(random_state=0, class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = X_train.columns.to_list()\n",
    "\n",
    "def get_score(model, X, y, X_test, y_test):\n",
    "    model.fit(X, y)\n",
    "    y_pred = model.predict_proba(X_test)[:,1]\n",
    "    score = roc_auc_score(y_test, y_pred)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(413378, 37) (177162, 37) (413378,) (177162,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "source": [
    "## Encoders"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hashing encoder\n",
    "# n_components_list = np.arange(100, 4000, 100).tolist()\n",
    "n_components_list = [1000]\n",
    "n_components_list_str = [str(i) for i in n_components_list]\n",
    "\n",
    "fh_model_scores = []\n",
    "\n",
    "for n_components in n_components_list:\n",
    "    hashing_enc = ce.HashingEncoder(cols=columns, n_components=n_components, max_process=6).fit(X_train, y_train)\n",
    "\n",
    "    X_train_hashing = hashing_enc.transform(X_train.reset_index(drop=True))\n",
    "    X_test_hashing = hashing_enc.transform(X_test.reset_index(drop=True))\n",
    "\n",
    "    fe_model_score = get_score(brf, X_train_hashing, y_train, X_test_hashing, y_test)\n",
    "    fh_model_scores.append(fe_model_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'\\n# leave one out encoder\\n# %%time\\nleaveone_enc = ce.LeaveOneOutEncoder(cols=columns, sigma=0.05).fit(X_train, y_train)\\n\\nX_train_leaveone = leaveone_enc.transform(X_train.reset_index(drop=True))\\nX_test_leaveone = leaveone_enc.transform(X_test.reset_index(drop=True))\\n    \\n\\nfe_model_score = get_score(brf, X_train_leaveone, y_train, X_test_leaveone, y_test)\\n'"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "'''\n",
    "# leave one out encoder\n",
    "# %%time\n",
    "leaveone_enc = ce.LeaveOneOutEncoder(cols=columns, sigma=0.05).fit(X_train, y_train)\n",
    "\n",
    "X_train_leaveone = leaveone_enc.transform(X_train.reset_index(drop=True))\n",
    "X_test_leaveone = leaveone_enc.transform(X_test.reset_index(drop=True))\n",
    "    \n",
    "\n",
    "fe_model_score = get_score(brf, X_train_leaveone, y_train, X_test_leaveone, y_test)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'\\n# binary encoder\\nbinary_enc = ce.BinaryEncoder(cols=columns, drop_invariant=True).fit(X_train, y_train)\\n\\nX_train_binary = binary_enc.transform(X_train.reset_index(drop=True))\\nX_test_binary = binary_enc.transform(X_test.reset_index(drop=True))\\n    \\n\\nfe_model_score = get_score(brf, X_train_binary, y_train, X_test_binary, y_test)\\n'"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "'''\n",
    "# binary encoder\n",
    "binary_enc = ce.BinaryEncoder(cols=columns, drop_invariant=True).fit(X_train, y_train)\n",
    "\n",
    "X_train_binary = binary_enc.transform(X_train.reset_index(drop=True))\n",
    "X_test_binary = binary_enc.transform(X_test.reset_index(drop=True))\n",
    "    \n",
    "\n",
    "fe_model_score = get_score(brf, X_train_binary, y_train, X_test_binary, y_test)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'\\n# target encoder\\ntarget_enc = ce.TargetEncoder(cols=columns, min_samples_leaf=100.000, smoothing=1).fit(X_train, y_train)\\n\\nX_train_target = target_enc.transform(X_train.reset_index(drop=True))\\nX_test_target = target_enc.transform(X_test.reset_index(drop=True))\\n    \\n\\nfe_model_score = get_score(brf, X_train_target, y_train, X_test_target, y_test)\\n'"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "'''\n",
    "# target encoder\n",
    "target_enc = ce.TargetEncoder(cols=columns, min_samples_leaf=100.000, smoothing=1).fit(X_train, y_train)\n",
    "\n",
    "X_train_target = target_enc.transform(X_train.reset_index(drop=True))\n",
    "X_test_target = target_enc.transform(X_test.reset_index(drop=True))\n",
    "    \n",
    "\n",
    "fe_model_score = get_score(brf, X_train_target, y_train, X_test_target, y_test)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'\\n# weight of evidence encoder\\nevidence_enc = ce.WOEEncoder(cols=columns, randomized=True, sigma=0.6, regularization=0.6).fit(X_train, y_train)\\n\\n#randomized=True, sigma=0.1, regularization=0.1\\n\\nX_train_evidence = evidence_enc.transform(X_train.reset_index(drop=True))\\nX_test_evidence = evidence_enc.transform(X_test.reset_index(drop=True))\\n    \\n\\nfe_model_score = get_score(brf, X_train_evidence, y_train, X_test_evidence, y_test)\\n'"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "'''\n",
    "# weight of evidence encoder\n",
    "evidence_enc = ce.WOEEncoder(cols=columns, randomized=True, sigma=0.6, regularization=0.6).fit(X_train, y_train)\n",
    "\n",
    "#randomized=True, sigma=0.1, regularization=0.1\n",
    "\n",
    "X_train_evidence = evidence_enc.transform(X_train.reset_index(drop=True))\n",
    "X_test_evidence = evidence_enc.transform(X_test.reset_index(drop=True))\n",
    "    \n",
    "\n",
    "fe_model_score = get_score(brf, X_train_evidence, y_train, X_test_evidence, y_test)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.figure(figsize=(8, 5))\n",
    "#plt.plot(n_components_list_str, fh_model_scores, linewidth=3)\n",
    "#plt.title('n_compontents vs roc_auc for feature hashing with logistic regression')\n",
    "#plt.xlabel('n_components')\n",
    "#plt.ylabel('score')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[0.9258916704316547]"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "fh_model_scores\n",
    "#fe_model_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n\n           0       0.99      0.85      0.92    170910\n           1       0.17      0.86      0.29      6252\n\n    accuracy                           0.85    177162\n   macro avg       0.58      0.86      0.60    177162\nweighted avg       0.97      0.85      0.89    177162\n\n"
     ]
    }
   ],
   "source": [
    "y_pred = brf.predict(X_test_hashing)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tn: 145380\nfp: 25530\nfn: 878\ntp: 5374\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_true=y_test, y_pred=y_pred).ravel()\n",
    "\n",
    "print(f'tn: {tn}')\n",
    "print(f'fp: {fp}')\n",
    "print(f'fn: {fn}')\n",
    "print(f'tp: {tp}')"
   ]
  },
  {
   "source": [
    "### Test submission"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Wall time: 25.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "idee_test = pd.read_csv('test_identity.csv')\n",
    "transaction_test = pd.read_csv('test_transaction.csv') \n",
    "merge_test = transaction_test.merge(idee_test, how='outer', on='TransactionID')\n",
    "objects_test = merge_test.select_dtypes('object')\n",
    "objects_test = objects_test.join(merge_test[['card1', 'card2', 'card3', 'card5', 'addr1', 'addr2']])\n",
    "objects_test.fillna(\"Unknown\", inplace=True)\n",
    "objects_test = objects_test.astype('object')\n",
    "#objects_test = objects_test.astype('category')\n",
    "objects_test.columns = X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2_hashed = hashing_enc.transform(objects_test.reset_index(drop=True))\n",
    "#X2_evidence = evidence_enc.transform(objects_test.reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Wall time: 6.47 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = brf.predict(X2_hashed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        TransactionID  isFraud\n",
       "0             3663549        0\n",
       "1             3663550        1\n",
       "2             3663551        0\n",
       "3             3663552        0\n",
       "4             3663553        0\n",
       "...               ...      ...\n",
       "506686        4170235        1\n",
       "506687        4170236        0\n",
       "506688        4170237        0\n",
       "506689        4170238        0\n",
       "506690        4170239        1\n",
       "\n",
       "[506691 rows x 2 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>TransactionID</th>\n      <th>isFraud</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3663549</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3663550</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3663551</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3663552</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3663553</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>506686</th>\n      <td>4170235</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>506687</th>\n      <td>4170236</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>506688</th>\n      <td>4170237</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>506689</th>\n      <td>4170238</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>506690</th>\n      <td>4170239</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>506691 rows × 2 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "sub_data = {'TransactionID': np.array(merge_test.TransactionID), 'isFraud': y_pred}\n",
    "submission = pd.DataFrame(data=sub_data)\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv', index=False, doublequote=False, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#growth_rate = np.exp(np.diff(np.log(fh_logit_scores))) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#growth_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.figure(figsize=(8, 5))\n",
    "#plt.plot(n_components_list_str, growth_rate, linewidth=3)\n",
    "#plt.title('n_compontents vs growth_rate for feature hashing with logistic regression')\n",
    "#plt.xlabel('n_components')\n",
    "#plt.ylabel('GRate')\n",
    "#plt.show()"
   ]
  }
 ]
}