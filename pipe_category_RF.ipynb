{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit (conda)",
   "metadata": {
    "interpreter": {
     "hash": "e55c523ff2bbb618fbe24525858e914d64cf59e5e868795d6cd1f87bc7cc8e1c"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lib Imports\n",
    "import pandas as pd\n",
    "import os\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, roc_auc_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "import category_encoders as ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting Pandas column display option\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Wall time: 34.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "idee = pd.read_csv('train_identity.csv')\n",
    "transaction = pd.read_csv('train_transaction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nInt64Index: 590540 entries, 0 to 590539\nData columns (total 38 columns):\n #   Column         Non-Null Count   Dtype   \n---  ------         --------------   -----   \n 0   ProductCD      590540 non-null  category\n 1   card4          590540 non-null  category\n 2   card6          590540 non-null  category\n 3   P_emaildomain  590540 non-null  category\n 4   R_emaildomain  590540 non-null  category\n 5   M1             590540 non-null  category\n 6   M2             590540 non-null  category\n 7   M3             590540 non-null  category\n 8   M4             590540 non-null  category\n 9   M5             590540 non-null  category\n 10  M6             590540 non-null  category\n 11  M7             590540 non-null  category\n 12  M8             590540 non-null  category\n 13  M9             590540 non-null  category\n 14  id_12          590540 non-null  category\n 15  id_15          590540 non-null  category\n 16  id_16          590540 non-null  category\n 17  id_23          590540 non-null  category\n 18  id_27          590540 non-null  category\n 19  id_28          590540 non-null  category\n 20  id_29          590540 non-null  category\n 21  id_30          590540 non-null  category\n 22  id_31          590540 non-null  category\n 23  id_33          590540 non-null  category\n 24  id_34          590540 non-null  category\n 25  id_35          590540 non-null  category\n 26  id_36          590540 non-null  category\n 27  id_37          590540 non-null  category\n 28  id_38          590540 non-null  category\n 29  DeviceType     590540 non-null  category\n 30  DeviceInfo     590540 non-null  category\n 31  card1          590540 non-null  category\n 32  card2          590540 non-null  category\n 33  card3          590540 non-null  category\n 34  card5          590540 non-null  category\n 35  addr1          590540 non-null  category\n 36  addr2          590540 non-null  category\n 37  isFraud        590540 non-null  category\ndtypes: category(38)\nmemory usage: 46.2 MB\nNone\nWall time: 19 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def pipeline(idee, transaction):\n",
    "    merge = transaction.merge(idee, how='outer', on='TransactionID')\n",
    "    objects = merge.select_dtypes('object')\n",
    "    objects = objects.join(merge[['card1', 'card2', 'card3', 'card5', 'addr1', 'addr2']])\n",
    "    objects['isFraud'] = merge['isFraud']\n",
    "    objects.fillna(\"Unknown\", inplace=True)\n",
    "    objects = objects.astype('category')\n",
    "    print(objects.info())\n",
    "    return objects\n",
    "objects = pipeline(idee,transaction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(590540, 28)"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "objects.drop(columns=['M4','id_15','id_16','id_28','id_29','id_35','id_36','id_38','DeviceType','DeviceInfo'], inplace=True)\n",
    "objects.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Wall time: 286 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X  = objects.drop(columns='isFraud')\n",
    "y = objects['isFraud'].astype('int')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=123)\n",
    "\n",
    "bbc = BalancedBaggingClassifier(base_estimator=DecisionTreeClassifier(),\n",
    "                                sampling_strategy='auto',\n",
    "                                replacement=False,\n",
    "                                random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = X_train.columns.to_list()\n",
    "\n",
    "def get_score(model, X, y, X_test, y_test):\n",
    "    model.fit(X, y)\n",
    "    y_pred = model.predict_proba(X_test)[:,1]\n",
    "    score = roc_auc_score(y_test, y_pred)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(413378, 27) (177162, 27) (413378,) (177162,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'logit' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'logit' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# n_components_list = np.arange(100, 4000, 100).tolist()\n",
    "n_components_list = [100]\n",
    "n_components_list_str = [str(i) for i in n_components_list]\n",
    "\n",
    "fh_logit_scores = []\n",
    "\n",
    "for n_components in n_components_list:\n",
    "    hashing_enc = ce.HashingEncoder(cols=columns, n_components=n_components).fit(X_train, y_train)\n",
    "    \n",
    "    X_train_hashing = hashing_enc.transform(X_train.reset_index(drop=True))\n",
    "    X_test_hashing = hashing_enc.transform(X_test.reset_index(drop=True))\n",
    "    \n",
    "    fe_logit_score = get_score(bbc, X_train_hashing, y_train, X_test_hashing, y_test)\n",
    "    fh_logit_scores.append(fe_logit_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(n_components_list_str, fh_logit_scores, linewidth=3)\n",
    "plt.title('n_compontents vs roc_auc for feature hashing with logistic regression')\n",
    "plt.xlabel('n_components')\n",
    "plt.ylabel('score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fh_logit_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "growth_rate = np.exp(np.diff(np.log(fh_logit_scores))) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "growth_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(n_components_list_str, growth_rate, linewidth=3)\n",
    "plt.title('n_compontents vs growth_rate for feature hashing with logistic regression')\n",
    "plt.xlabel('n_components')\n",
    "plt.ylabel('GRate')\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "## Test dataset benchmarking"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "hashing_enc = ce.HashingEncoder(cols=columns, n_components=1700, max_process=4).fit(X_train, y_train)\n",
    "X_train_hashing = hashing_enc.transform(X_train.reset_index(drop=True))\n",
    "X_test_hashing = hashing_enc.transform(X_test.reset_index(drop=True))\n",
    "print(X_train_hashing.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "idee_test = pd.read_csv('test_identity.csv')\n",
    "transaction_test = pd.read_csv('test_transaction.csv') \n",
    "merge_test = transaction_test.merge(idee_test, how='outer', on='TransactionID')\n",
    "objects_test = merge_test.select_dtypes('object')\n",
    "objects_test.fillna(\"Unknown\", inplace=True)\n",
    "objects_test = objects_test.astype('category')\n",
    "objects_test.columns = X_train.columns\n",
    "print(objects_test.info())\n",
    "del idee_test, transaction_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2_hashed = hashing_enc.transform(objects_test.reset_index(drop=True), override_return_df=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "X2_hashed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "logit.fit(X_train_hashing, y_train)\n",
    "y_pred_train = logit.predict(X_test_hashing)\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_pred_train, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "y_pred = logit.predict(X2_hashed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  }
 ]
}